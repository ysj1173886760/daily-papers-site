<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents - Daily AI Papers</title>
    <link rel="stylesheet" href="/assets/style.css">
    <link rel="stylesheet" href="/assets/highlight.css">
    <link rel="alternate" type="application/rss+xml" title="Daily AI Papers" href="/rss.xml">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fafafa;
        }
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
        }
        header h1 {
            margin: 0;
            font-size: 2.5rem;
        }
        header p {
            margin: 0.5rem 0 0 0;
            opacity: 0.9;
        }
        nav {
            margin-top: 1rem;
        }
        nav a {
            color: white;
            text-decoration: none;
            margin: 0 1rem;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            background: rgba(255,255,255,0.2);
        }
        nav a:hover {
            background: rgba(255,255,255,0.3);
        }
        .paper-card {
            background: white;
            border-radius: 10px;
            padding: 2rem;
            margin: 2rem 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-left: 4px solid #667eea;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9rem;
            margin-bottom: 1rem;
        }
        .paper-title {
            font-size: 1.4rem;
            font-weight: bold;
            color: #333;
            margin-bottom: 1rem;
        }
        .paper-summary {
            color: #444;
            line-height: 1.8;
            font-size: 1rem;
        }
        .paper-summary h1 {
            color: #667eea;
            font-size: 1.4rem;
            margin: 2rem 0 1rem 0;
            padding: 0.8rem 1rem;
            background: linear-gradient(90deg, #f8f9ff 0%, #ffffff 100%);
            border-left: 4px solid #667eea;
            border-radius: 0 6px 6px 0;
        }
        .paper-summary h2 {
            color: #5a67d8;
            font-size: 1.2rem;
            margin: 1.5rem 0 0.8rem 0;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e2e8f0;
        }
        .paper-summary h3 {
            color: #4a5568;
            font-size: 1.1rem;
            margin: 1.2rem 0 0.6rem 0;
        }
        .paper-summary p {
            margin: 1rem 0;
            text-align: justify;
        }
        .paper-summary ul, .paper-summary ol {
            margin: 1rem 0;
            padding-left: 2rem;
        }
        .paper-summary li {
            margin: 0.5rem 0;
            line-height: 1.6;
        }
        .paper-summary strong {
            color: #2d3748;
            font-weight: 600;
        }
        .paper-summary em {
            color: #4a5568;
            font-style: italic;
        }
        .paper-summary blockquote {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: #f7fafc;
            border-left: 4px solid #667eea;
            border-radius: 0 6px 6px 0;
        }
        .paper-summary code {
            background: #f1f5f9;
            color: #475569;
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-family: 'Fira Code', 'Monaco', 'Consolas', 'Ubuntu Mono', monospace;
            font-size: 0.9rem;
            border: 1px solid #e2e8f0;
        }
        .paper-summary pre {
            background: #0f172a;
            color: #f8fafc;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
            border: 1px solid #334155;
            position: relative;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        .paper-summary pre::before {
            content: 'Python';
            position: absolute;
            top: 0;
            right: 0;
            background: #667eea;
            color: white;
            padding: 0.25rem 0.75rem;
            font-size: 0.75rem;
            border-radius: 0 8px 0 8px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        }
        .paper-summary pre code {
            background: none;
            color: inherit;
            padding: 0;
            border: none;
            font-size: 0.95rem;
            line-height: 1.6;
        }
        .paper-summary .codehilite {
            margin: 1.5rem 0;
        }
        .paper-summary .codehilite pre {
            margin: 0;
        }
        /* 语法高亮颜色 */
        .paper-summary .codehilite .c { color: #6b7280; } /* 注释 */
        .paper-summary .codehilite .k { color: #8b5cf6; } /* 关键字 */
        .paper-summary .codehilite .s { color: #10b981; } /* 字符串 */
        .paper-summary .codehilite .n { color: #f8fafc; } /* 变量名 */
        .paper-summary .codehilite .o { color: #f59e0b; } /* 操作符 */
        .paper-summary .codehilite .p { color: #94a3b8; } /* 标点 */
        .paper-summary .codehilite .m { color: #ef4444; } /* 数字 */
        .paper-summary .codehilite .nf { color: #06b6d4; } /* 函数名 */
        .paper-links {
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 1px solid #eee;
        }
        .paper-links a {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            text-decoration: none;
            border-radius: 5px;
            margin-right: 1rem;
            font-size: 0.9rem;
        }
        .paper-links a:hover {
            background: #5a6fd8;
        }
        footer {
            text-align: center;
            margin-top: 3rem;
            padding: 2rem;
            color: #666;
            border-top: 1px solid #eee;
        }
    </style>
</head>
<body>
    <header>
        <h1>Daily AI Papers</h1>
        <p>2025年08月03日 - RAG_test 论文</p>
        <nav>
            <a href="/">首页</a>
            <a href="/rss.xml">RSS订阅</a>
            <a href="/about.html">关于</a>
        </nav>
    </header>

    <main>
        <article class="paper-card">
            <div class="paper-meta">
                <span>发布: 2025-07-31</span> | 
                <span>更新: 2025-07-31</span> |
                <span>分类: cs.CV</span> |
                <span>arXiv ID: 2507.23242v1</span>
            </div>
            
            <h2 class="paper-title">Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents</h2>
            
            <div class="paper-summary">
                <h1 id="_1">问题定义</h1>
<p><strong>problem</strong></p>
<ol>
<li>论文要解决的具体问题是：在Retrieval-Augmented Generation (RAG)系统中，针对不同类型的检索器（ lexical、语义、混合、多模态），如何实现无需人工标注的查询重写优化，以提升非结构化真实世界文档的检索性能。</li>
<li>这个问题的重要性体现在：查询重写是RAG系统的核心组件，直接影响检索结果的相关性和生成质量；而现有方法依赖人工标注，难以扩展到真实世界的非结构化数据（如PDF、幻灯片等），且无法适应不同检索器的特性（如lexical依赖关键词，语义依赖上下文）。</li>
<li>目前存在的挑战或困难：(1) 现有查询重写方法需要大量人工标注数据，成本高且难以规模化；(2) 难以适应不同检索器的特性（如lexical vs 语义检索器的查询需求差异）；(3) 多模态文档（如图像化文档）的查询重写缺乏有效解决方案；(4) 语义和混合检索器的查询重写效果差，训练目标与检索器特性不匹配。</li>
</ol>
<h1 id="_2">研究背景</h1>
<p><strong>background</strong></p>
<ol>
<li>前人在这个领域的研究成果包括：(1) RAG框架的提出（Lewis et al. 2020），将检索与生成结合；(2) 传统查询重写方法（如 heuristic扩展、统计方法）；(3) 近年来的学习型查询重写方法（如 neural network、强化学习（RL）），例如Wang et al. 2025用显式反馈训练重写器，Jin et al. 2025用RL优化查询以提升最终答案质量。</li>
<li>现有方法的优点和局限性：(1) 传统方法（如 heuristic）简单易实现，但依赖人工经验，难以适应复杂场景；(2) 学习型方法（如 supervised learning）在结构化数据上有效，但需要大量标注数据，难以扩展到真实世界非结构化数据；(3) 现有RL方法（如 Jin et al. 2025）关注最终答案质量，但未针对检索器特性优化，难以适应不同检索器。</li>
<li>当前技术水平：查询重写在结构化文本数据（如新闻、维基百科）上已取得较好效果，但在非结构化真实世界文档（如工业PDF、幻灯片）和多模态数据（如图像化文档）上仍存在性能瓶颈；针对不同检索器的个性化查询重写方法尚未成熟。</li>
</ol>
<h1 id="_3">创新来源</h1>
<p><strong>idea_source</strong></p>
<ol>
<li>核心思路来自于：用强化学习（RL）解决查询重写的个性化问题，无需人工标注，通过合成数据训练针对特定检索器的重写器。</li>
<li>灵感来自于：(1) RL在NLP生成任务中的成功应用（如文本摘要、机器翻译），其通过奖励函数优化生成结果；(2) 大模型（LLM）在数据合成中的能力，可自动生成场景-问题对，替代人工标注。</li>
<li>作者产生创新想法的过程：观察到现有查询重写方法依赖人工标注，难以适应不同检索器和真实世界数据，因此提出用LLM合成场景-问题对（替代人工标注），并用RL针对特定检索器优化重写器（匹配检索器的表示空间）。</li>
</ol>
<h1 id="_4">解决方案</h1>
<p><strong>solution</strong></p>
<ol>
<li>论文提出的具体技术方案是：Generalized Reinforcement Learning for Retriever-Specific Query Rewriter (RL-QR)，分为两步：(1) 用大模型合成场景-问题对（模拟真实用户的长查询）；(2) 用强化学习（GRPO算法）训练针对特定检索器的查询重写器，优化目标是提升检索性能（NDCG@3）并保证格式正确性。</li>
<li>关键技术细节和实现要点：(1) 场景-问题合成：用LLM（如Qwen2.5-VL-72B、Qwen3-32B）解析原始文档（多模态或文本），生成场景、问题和答案，合并场景和问题作为查询；(2) RL训练：针对不同检索器（多模态、 lexical、语义、混合）训练不同的重写器，用GRPO算法优化，奖励函数结合检索奖励（NDCG@3）和格式惩罚（如冗余内容扣分）；(3) 模块化设计：重写器与检索器解耦，支持不同检索器和模态（多模态、文本）。</li>
</ol>
<h1 id="_5">实验验证</h1>
<p><strong>experiment</strong></p>
<ol>
<li>实验设计和安排：实现了两个RAG系统（多模态RAG、文本-based RAG），分别测试针对多模态检索器（ColQwen2.5-3B）、lexical检索器（ixi-RAG lexical）、语义检索器（ixi-RAG semantic）、混合检索器（ixi-RAG hybrid）的重写器性能。</li>
<li>使用的数据集、基准和评估指标：(1) 数据集：2145篇工业内部非结构化文档（PDF、Word、幻灯片），合成了多模态训练数据Dmm（1609条）和文本训练数据Dtm（2980条）；(2) 基准：原始查询、Qwen3-4B（无监督重写）、其他检索器的重写器（如RL-QRlexical用于语义检索器）；(3) 评估指标：NDCG@3（衡量检索结果的相关性和排序质量）。</li>
<li>实验结果：(1) 多模态RAG：RL-QRmulti-modal的NDCG@3为82.10，比原始查询（73.84）提升11%；(2) 文本-based RAG（lexical检索器）：RL-QRlexical的NDCG@3为79.66，比原始查询（72.90）提升9%；(3) 语义和混合检索器：RL-QRsemantic和RL-QRhybrid的性能未提升（甚至下降），说明训练目标与检索器特性不匹配。实验结果有效证明了方案在多模态和lexical检索器上的可行性，但语义和混合检索器仍需改进。</li>
</ol>
<h1 id="_6">研究结论</h1>
<p><strong>conclusion</strong></p>
<ol>
<li>重要结论：(1) RL-QR无需人工标注，可有效提升多模态和lexical检索器的检索性能；(2) 针对特定检索器的个性化重写器优于通用重写器（如Qwen3-4B）；(3) 语义和混合检索器的查询重写需优化训练目标（如结合推理型检索器）。</li>
<li>主要贡献和成果：(1) 提出了通用的RL查询重写框架（RL-QR），支持不同检索器和模态；(2) 实现了无需人工标注的查询重写，适应真实世界非结构化数据；(3) 在工业RAG系统（ixi-RAG）上验证了有效性，多模态和lexical检索器性能显著提升。</li>
<li>对领域发展的意义：推动了RAG系统在真实世界的应用，降低了查询重写的成本（无需人工标注），提升了系统的模块化和可维护性（重写器与检索器解耦）。</li>
</ol>
<h1 id="_7">未来展望</h1>
<p><strong>future_work</strong></p>
<ol>
<li>当前工作的局限性：(1) 语义和混合检索器的性能未提升，训练目标与检索器特性不匹配；(2) 训练数据量小（几千样本，单 epoch），可能导致过拟合或泛化能力差；(3) 重写查询长度过长（平均500+字符），可能影响检索效率。</li>
<li>未来可能的改进方向：(1) 优化语义检索器的训练目标，结合推理型检索器（如ReasonIR）的特性；(2) 增加训练数据量（如扩大合成数据规模），采用多 epoch训练；(3) 改进奖励函数，增加查询长度惩罚，控制重写查询的简洁性；(4) 探索更先进的RL算法（如PPO的变种），提升训练稳定性。</li>
<li>值得深入探索的问题：(1) 多模态查询重写的进一步优化（如图像化文档的语义理解）；(2) 查询重写与检索器的联合训练（如重写器适应检索器的表示空间）；(3) 真实用户查询的自适应重写（如根据用户反馈动态调整重写策略）。</li>
</ol>
<h1 id="_8">核心算法</h1>
<p>pseudocode: |</p>
<div class="codehilite"><pre><span></span><code>  <span class="c1"># 步骤1：合成场景-问题对（模拟真实用户长查询）</span>
  <span class="n">function</span> <span class="n">synthesize_queries</span><span class="p">(</span><span class="n">DB_raw</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">],</span> <span class="n">parser</span><span class="p">:</span> <span class="n">Parser</span><span class="p">,</span> <span class="n">llm</span><span class="p">:</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">DocumentIndex</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">      </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      输入：原始文档集合、文档解析器（多模态/文本）、大模型、提示模板</span>
<span class="sd">      输出：合成查询集合（关联文档索引）</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="n">parsed_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">DB_raw</span><span class="p">]</span>  <span class="c1"># 解析文档（多模态：图像嵌入；文本：文本 chunk）</span>
      <span class="n">synthetic_queries</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">parsed_docs</span><span class="p">:</span>
          <span class="c1"># 用大模型生成场景、问题、答案</span>
          <span class="n">llm_output</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">doc</span><span class="p">))</span>
          <span class="n">scenario</span> <span class="o">=</span> <span class="n">llm_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scenario&quot;</span><span class="p">)</span>
          <span class="n">question</span> <span class="o">=</span> <span class="n">llm_output</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;question&quot;</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">scenario</span> <span class="ow">and</span> <span class="n">question</span><span class="p">:</span>
              <span class="c1"># 合并场景和问题作为查询（模拟真实用户的长查询）</span>
              <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scenario</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s2">&quot;</span>
              <span class="n">synthetic_queries</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">doc</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">query</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">synthetic_queries</span>

  <span class="c1"># 步骤2：用GRPO训练针对特定检索器的查询重写器</span>
  <span class="n">function</span> <span class="n">train_query_rewriter</span><span class="p">(</span><span class="n">synthetic_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">DocumentIndex</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">retriever</span><span class="p">:</span> <span class="n">Retriever</span><span class="p">,</span> <span class="n">initial_model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span> <span class="n">lambda1</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">lambda2</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">grpo_hyperparams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">      </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      输入：合成数据（文档索引+查询）、检索器、初始重写器模型、奖励权重、GRPO超参数</span>
<span class="sd">      输出：训练后的重写器模型</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="n">model</span> <span class="o">=</span> <span class="n">initial_model</span>
      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">grpo_hyperparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
      <span class="n">epsilon</span> <span class="o">=</span> <span class="n">grpo_hyperparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epsilon&quot;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>  <span class="c1"># GRPO的剪辑参数</span>
      <span class="n">group_size</span> <span class="o">=</span> <span class="n">grpo_hyperparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;group_size&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># 每组采样的查询数量</span>

      <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">synthetic_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">grpo_hyperparams</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]):</span>
          <span class="n">doc_indices</span><span class="p">,</span> <span class="n">original_queries</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
          <span class="c1"># 生成重写查询（每组采样多个候选，用于GRPO的优势计算）</span>
          <span class="n">rewritten_queries</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">group_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">original_queries</span><span class="p">]</span>

          <span class="c1"># 计算每个重写查询的奖励</span>
          <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original_queries</span><span class="p">)):</span>
              <span class="n">doc_index</span> <span class="o">=</span> <span class="n">doc_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
              <span class="n">original_query</span> <span class="o">=</span> <span class="n">original_queries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
              <span class="n">group_queries</span> <span class="o">=</span> <span class="n">rewritten_queries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

              <span class="n">group_rewards</span> <span class="o">=</span> <span class="p">[]</span>
              <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">group_queries</span><span class="p">:</span>
                  <span class="c1"># 计算检索奖励（NDCG@3）：检索器返回的前3篇文档与目标文档的相关性</span>
                  <span class="n">retrieved_docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
                  <span class="n">ndcg</span> <span class="o">=</span> <span class="n">compute_ndcg</span><span class="p">(</span><span class="n">retrieved_docs</span><span class="p">,</span> <span class="n">doc_index</span><span class="p">)</span>

                  <span class="c1"># 计算格式惩罚：如果查询格式错误（如未包含必要信息）或冗余，扣分</span>
                  <span class="n">penalty</span> <span class="o">=</span> <span class="mf">0.0</span>
                  <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid_format</span><span class="p">(</span><span class="n">q</span><span class="p">):</span>
                      <span class="n">penalty</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>  <span class="c1"># 格式错误的严重惩罚</span>
                  <span class="k">elif</span> <span class="n">has_redundancy</span><span class="p">(</span><span class="n">q</span><span class="p">):</span>
                      <span class="n">penalty</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">remove_redundancy</span><span class="p">(</span><span class="n">q</span><span class="p">)))</span>  <span class="c1"># 冗余长度越长，惩罚越大</span>

                  <span class="c1"># 总奖励：检索奖励（lambda1加权）+ 格式惩罚（lambda2加权）</span>
                  <span class="n">total_reward</span> <span class="o">=</span> <span class="n">lambda1</span> <span class="o">*</span> <span class="n">ndcg</span> <span class="o">+</span> <span class="n">lambda2</span> <span class="o">*</span> <span class="n">penalty</span>
                  <span class="n">group_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>

              <span class="c1"># 计算优势函数（GRPO需要）</span>
              <span class="n">advantages</span> <span class="o">=</span> <span class="n">compute_advantages</span><span class="p">(</span><span class="n">group_rewards</span><span class="p">,</span> <span class="n">grpo_hyperparams</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">])</span>
              <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">advantages</span><span class="p">)</span>

          <span class="c1"># 用GRPO更新模型参数</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">grpo_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rewritten_queries</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="k">return</span> <span class="n">model</span>

  <span class="c1"># 辅助函数：计算NDCG@3</span>
  <span class="n">function</span> <span class="n">compute_ndcg</span><span class="p">(</span><span class="n">retrieved_docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">],</span> <span class="n">target_doc_index</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">      </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      输入：检索到的文档列表（前3篇）、目标文档索引</span>
<span class="sd">      输出：NDCG@3分数</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="c1"># 构建相关性判断：目标文档为1，其他为0</span>
      <span class="n">relevance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">doc</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">target_doc_index</span> <span class="k">else</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">retrieved_docs</span><span class="p">]</span>
      <span class="c1"># 计算DCG@3</span>
      <span class="n">dcg</span> <span class="o">=</span> <span class="n">relevance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">relevance</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">log2</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">relevance</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">log2</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
      <span class="c1"># 计算理想DCG@3（目标文档排在第一位）</span>
      <span class="n">ideal_relevance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
      <span class="n">ideal_dcg</span> <span class="o">=</span> <span class="n">ideal_relevance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">ideal_relevance</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">log2</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">ideal_relevance</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">log2</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
      <span class="c1"># 避免除以零</span>
      <span class="n">ndcg</span> <span class="o">=</span> <span class="n">dcg</span> <span class="o">/</span> <span class="n">ideal_dcg</span> <span class="k">if</span> <span class="n">ideal_dcg</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
      <span class="k">return</span> <span class="n">ndcg</span>

  <span class="c1"># 辅助函数：GRPO的损失计算（简化版）</span>
  <span class="n">function</span> <span class="n">grpo_loss</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span> <span class="n">rewritten_queries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">advantages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">      </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      输入：模型、重写查询组、优势函数值、剪辑参数</span>
<span class="sd">      输出：GRPO损失</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewritten_queries</span><span class="p">)):</span>
          <span class="n">group_queries</span> <span class="o">=</span> <span class="n">rewritten_queries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
          <span class="n">group_advantages</span> <span class="o">=</span> <span class="n">advantages</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

          <span class="c1"># 计算每个查询的概率（模型生成该查询的概率）</span>
          <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">compute_probability</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">group_queries</span><span class="p">]</span>
          <span class="n">old_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">compute_old_probability</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">group_queries</span><span class="p">]</span>  <span class="c1"># 用旧模型计算概率（GRPO的需要）</span>

          <span class="c1"># 计算概率比和剪辑</span>
          <span class="n">ratios</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="o">/</span> <span class="n">op</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">old_probs</span><span class="p">)]</span>
          <span class="n">clipped_ratios</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">ratios</span><span class="p">]</span>

          <span class="c1"># 计算损失：-min(ratio*adv, clipped_ratio*adv)</span>
          <span class="n">group_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">group_advantages</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">clipped_ratios</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">group_advantages</span><span class="p">)))</span>
          <span class="n">loss</span> <span class="o">+=</span> <span class="n">group_loss</span>

      <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewritten_queries</span><span class="p">)</span>
</code></pre></div>
            </div>
            
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2507.23242" target="_blank">arXiv原文</a>
                <a href="http://arxiv.org/pdf/2507.23242" target="_blank">PDF下载</a>
            </div>
        </article>
    </main>

    <footer>
        <p>Generated by Daily Paper Processing System | Template: V2</p>
        <p>数据来源: arXiv | 分析引擎: Large Language Model</p>
    </footer>
</body>
</html>